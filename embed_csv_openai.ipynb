{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeds cleaned CSVs using OpenAI's Ada-002 model\n",
    "# Since the model has a token limit, the first 9000 characters are embedded if the model throws an error\n",
    "# Only cleaned data that is over 85 characters, and recognized as english using Langdetect are embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import math\n",
    "import time\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(input):\n",
    "    response = openai.Embedding.create(\n",
    "    input=input,\n",
    "    model=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed Concatenated Segments\n",
    "all_clean = 0\n",
    "all_end = 0\n",
    "for num, f in enumerate(sorted(os.listdir('Cleaned By ID'), key=len)):\n",
    "    print(num+1, end = '\\t')\n",
    "    print('ID: ', str(f.rstrip('.csv')).ljust(10), end = '')\n",
    "    start = time.time()\n",
    "\n",
    "    if f in os.listdir('OpenAI Concat Embedded By ID'):\n",
    "        print(\"ALREADY EMBEDDED\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(f'Cleaned By ID/{f}')\n",
    "    df = df.dropna(subset=['Cleaned'])\n",
    "    df['Cleaned'] = df['Cleaned'].apply(lambda x: ast.literal_eval(x))\n",
    "    df['Cleaned'] = df['Cleaned'].apply(lambda x: '. '.join(x))\n",
    "    df = df[df['Cleaned'] != '']\n",
    "    count_cleaned = len(df)\n",
    "    all_clean += count_cleaned\n",
    "    print('\\tCleaned: ', str(len(df)).ljust(7), end= '')\n",
    "\n",
    "    df['Eng'] = df['Cleaned'].apply(lambda x: detect(x) == 'en')\n",
    "    df = df[(df['Eng'] == True)]\n",
    "    print('English: ', str(len(df)).ljust(7), end= '')\n",
    "\n",
    "    df = df[df['Cleaned'].str.len() > 85]\n",
    "    print('Over 85: ', str(len(df)).ljust(7), end= '')\n",
    "    all_end += len(df)\n",
    "    try:\n",
    "        print('Ratio:', round(len(df) / count_cleaned, 3), end= '')\n",
    "    except:\n",
    "        print('Ratio:', 0)\n",
    "    df = df.drop(columns=['Eng']).reset_index()\n",
    "    df['Embedding'] = None\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            emb = embed(row['Cleaned'])\n",
    "        except:\n",
    "            emb = embed(row['Cleaned'][:9000])\n",
    "        df.at[i, 'Embedding'] = emb\n",
    "        print(f'\\t{i}', detect(row['Cleaned']) == 'en')\n",
    "\n",
    "    # df.drop(columns=['index', 'Segments']).to_csv(f'Embedded By ID/{f}', index = False)\n",
    "    # print(time.time() - start, 'seconds')\n",
    "print('\\n\\n ---- Total Ratio:', round(all_end / all_clean, 3), '----')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "055b01331e6aaed25ee87e2ba8c23bcef7463dead3293343036df99fa24c5bd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
